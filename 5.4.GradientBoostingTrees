import gzip
import json
import pickle

import ipywidgets as widgets
import pandas as pd
import wqet_grader
from imblearn.over_sampling import RandomOverSampler
from IPython.display import VimeoVideo
from ipywidgets import interact
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.impute import SimpleImputer
from sklearn.metrics import (
    ConfusionMatrixDisplay,
    classification_report,
    confusion_matrix,
)
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.pipeline import make_pipeline
from teaching_tools.widgets import ConfusionMatrixWidget

def wrangle(filename):
    # Open file and load JSON
    with gzip.open(filename, "r") as data_file:    
        data = json.load(data_file)
    df = pd.DataFrame().from_dict(data["data"]).set_index("company_id")
    return df

df = wrangle("data/poland-bankruptcy-data-2009.json.gz")

target = "bankrupt"
X = df.drop(columns = target)
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

over_sampler = RandomOverSampler(random_state=42)
X_train_over, y_train_over = over_sampler.fit_resample(X_train, y_train)

acc_baseline = y_train.value_counts(normalize=True).max()

clf = make_pipeline(SimpleImputer(), GradientBoostingClassifier())

params = {
    "simpleimputer__strategy": ["mean", "median"],
    "gradientboostingclassifier__n_estimators": range(20, 31, 5),
    "gradientboostingclassifier__max_depth": range(2,5)
}

model = GridSearchCV(
    clf,
    param_grid = params,
    cv=5,
    n_jobs = -1,
    verbose =1
)

model.fit(X_train_over, y_train_over)

cv_results = pd.DataFrame(model.cv_results_)
results.sort_values("rank_test_score").head(10)

model.best_params_

acc_train = model.score(X_train_over, y_train_over)
acc_test = model.score(X_test, y_test)

ConfusionMatrixDisplay.from_estimator(model, X_test, y_test);

# Print classification report
print(classification_report(y_test, model.predict(X_test)))

def make_cnf_matrix(threshold):
    y_pred_proba = model.predict_proba(X_test)[:, -1]
    y_pred = y_pred_proba > threshold
    conf_matrix=confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = conf_matrix.ravel()
    print(f"Profit: €{tp*100_000_000}")
    print(f"Lossers: €{fp*250_000_000}")
    print(f"Total: €{tp*100_000_000 - fp*250_000_000 }")
    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, colorbar=False)
    pass


thresh_widget = widgets.FloatSlider(min=0, max=1, value=0.5, step=0.05)

interact(make_cnf_matrix, threshold=thresh_widget);


# Save model
with open("model-5-4.pkl", "wb") as f:
    pickle.dump(model, f)

def make_predictions(data_filepath, model_filepath):
    # Wrangle JSON file
    X_test = wrangle(data_filepath)
    # Load model
    with open(model_filepath, "rb") as f:
        model = pickle.load(f)
    # Generate predictions
    y_test_pred = model.predict(X_test)
    # Put predictions into Series with name "bankrupt", and same index as X_test
    y_test_pred = pd.Series(y_test_pred, index=X_test.index, name= "bankrupt")
    return y_test_pred

y_test_pred = make_predictions(
    data_filepath="data/poland-bankruptcy-data-2009-mvp-features.json.gz",
    model_filepath="model-5-3.pkl",
)

print("predictions shape:", y_test_pred.shape)
y_test_pred.head()

